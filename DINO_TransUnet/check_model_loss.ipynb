{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"check_model_loss.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM5gdh7d+zDiGWUcx6Dlw2K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XQ0RSOt820jz","executionInfo":{"status":"ok","timestamp":1644944309185,"user_tz":-120,"elapsed":24454,"user":{"displayName":"Evyatar Burshtein","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15042063365769237452"}},"outputId":"970b097e-5772-4868-d41b-6a020a057721"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","### Change to current directory ###\n","path ='/content/drive/MyDrive/Deep_learning/project/TransUnet_copy/'\n","transunet_model_path = '/content/drive/MyDrive/Deep_learning/project/trained_models/TransUNET_model - 20 epochs'\n","dino_model_path = '/content/drive/MyDrive/Deep_learning/project/trained_models/DINO_TransUNET_model - 20 epochs'\n"]},{"cell_type":"code","source":["%cd drive/MyDrive/Deep_learning/project/TransUnet_copy/\n","\n","# Installs\n","!pip install ml_collections medpy\n","\n","# Imports\n","import os\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn.modules.loss import CrossEntropyLoss\n","from torch.utils.data import DataLoader\n","import torch.backends.cudnn as cudnn\n","from tqdm import tqdm\n","from utils.utils import DiceLoss\n","from torchvision import transforms\n","from networks.vit_seg_modeling import VisionTransformer as ViT_seg\n","from networks.vit_seg_modeling import CONFIGS as CONFIGS_ViT_seg\n","from datasets.dataset_sartorius import Sartorius_dataset, RandomGenerator\n","from google.colab.patches import cv2_imshow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYVtxVKJAvdh","executionInfo":{"status":"ok","timestamp":1644944344686,"user_tz":-120,"elapsed":35504,"user":{"displayName":"Evyatar Burshtein","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15042063365769237452"}},"outputId":"882ca102-dd4d-43a8-9947-f63fb2f15769"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Deep_learning/project/TransUnet_copy\n","Collecting ml_collections\n","  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 3.2 MB/s \n","\u001b[?25hCollecting medpy\n","  Downloading MedPy-0.4.0.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 21.1 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from ml_collections) (1.0.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml_collections) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml_collections) (1.15.0)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml_collections) (0.5.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n","Collecting SimpleITK>=1.1.0\n","  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n","\u001b[K     |████████████████████████████████| 48.4 MB 1.9 MB/s \n","\u001b[?25hBuilding wheels for collected packages: ml-collections, medpy\n","  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=2512e6eaf2bb1803d31e1996616b0dfadd7d468629509efea672897fb7d23f86\n","  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n","  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for medpy: filename=MedPy-0.4.0-cp37-cp37m-linux_x86_64.whl size=754455 sha256=e962a3b304403ba3c5f8281cba8ba91dd1ba0cbf6440d43dc93faa65b8edf782\n","  Stored in directory: /root/.cache/pip/wheels/b0/57/3a/da1183f22a6afb42e11138daa6a759de233fd977a984333602\n","Successfully built ml-collections medpy\n","Installing collected packages: SimpleITK, ml-collections, medpy\n","Successfully installed SimpleITK-2.1.1 medpy-0.4.0 ml-collections-0.1.1\n"]}]},{"cell_type":"code","source":["# Dataset Definitions\n","train_base_dir = '/content/drive/MyDrive/Deep_learning/project/data/train_npz'\n","test_base_dir = '/content/drive/MyDrive/Deep_learning/project/data/test_npz'\n","list_dir = path + 'lists/lists_Sartorius/'\n","img_size = 224    # original image size [520, 704]\n","rand_seed = 1234\n","num_classes = 2\n","n_skip = 3\n","vit_name = 'R50-ViT-B_16'\n","vit_patches_size = 16\n","z_spacing = 1\n","deterministic = True\n","\n","\n","\n","db_train = Sartorius_dataset(base_dir=train_base_dir, list_dir=list_dir, split=\"train\",transform=transforms.Compose([RandomGenerator(output_size=[img_size, img_size])]))\n","\n","db_test = Sartorius_dataset(base_dir=test_base_dir, split=\"test\", list_dir=list_dir,transform=transforms.Compose([RandomGenerator(output_size=[img_size, img_size])]))\n","\n","def worker_init_fn(worker_id):\n","    random.seed(rand_seed + worker_id)\n"],"metadata":{"id":"787gLEFPAdMp","executionInfo":{"status":"ok","timestamp":1644944347066,"user_tz":-120,"elapsed":2384,"user":{"displayName":"Evyatar Burshtein","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15042063365769237452"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Set random seeds for reproducibility\n","random.seed(rand_seed)\n","np.random.seed(rand_seed)\n","torch.manual_seed(rand_seed)\n","torch.cuda.manual_seed(rand_seed)\n","\n","# Set model Configuration\n","config_vit = CONFIGS_ViT_seg[vit_name]\n","config_vit.n_classes = num_classes\n","config_vit.n_skip = n_skip\n","if vit_name.find('R50') != -1:\n","    config_vit.patches.grid = (int(img_size / vit_patches_size), int(img_size / vit_patches_size))\n","\n","# Load models\n","dino_model = torch.load(dino_model_path)\n","#transunet_model = torch.load(transunet_model_path) \n","\n","dino_model.train()\n","#transunet_model.eval()"],"metadata":{"id":"JA9kyx7SCFzj","executionInfo":{"status":"ok","timestamp":1644944368782,"user_tz":-120,"elapsed":21726,"user":{"displayName":"Evyatar Burshtein","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15042063365769237452"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c82a699-b0fb-481c-b72d-c5c256a8bf4f"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VisionTransformer(\n","  (transformer): Transformer(\n","    (embeddings): Embeddings(\n","      (hybrid_model): ResNetV2(\n","        (root): Sequential(\n","          (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","          (gn): GroupNorm(32, 64, eps=1e-06, affine=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (body): Sequential(\n","          (block1): Sequential(\n","            (unit1): PreActBottleneck(\n","              (gn1): GroupNorm(32, 64, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 64, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","              (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn_proj): GroupNorm(256, 256, eps=1e-05, affine=True)\n","            )\n","            (unit2): PreActBottleneck(\n","              (gn1): GroupNorm(32, 64, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 64, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit3): PreActBottleneck(\n","              (gn1): GroupNorm(32, 64, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 64, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","          )\n","          (block2): Sequential(\n","            (unit1): PreActBottleneck(\n","              (gn1): GroupNorm(32, 128, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 128, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 512, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","              (downsample): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","              (gn_proj): GroupNorm(512, 512, eps=1e-05, affine=True)\n","            )\n","            (unit2): PreActBottleneck(\n","              (gn1): GroupNorm(32, 128, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 128, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 512, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit3): PreActBottleneck(\n","              (gn1): GroupNorm(32, 128, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 128, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 512, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit4): PreActBottleneck(\n","              (gn1): GroupNorm(32, 128, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 128, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 512, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","          )\n","          (block3): Sequential(\n","            (unit1): PreActBottleneck(\n","              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","              (downsample): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","              (gn_proj): GroupNorm(1024, 1024, eps=1e-05, affine=True)\n","            )\n","            (unit2): PreActBottleneck(\n","              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit3): PreActBottleneck(\n","              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit4): PreActBottleneck(\n","              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit5): PreActBottleneck(\n","              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit6): PreActBottleneck(\n","              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit7): PreActBottleneck(\n","              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit8): PreActBottleneck(\n","              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","            (unit9): PreActBottleneck(\n","              (gn1): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (gn2): GroupNorm(32, 256, eps=1e-06, affine=True)\n","              (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (gn3): GroupNorm(32, 1024, eps=1e-06, affine=True)\n","              (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (relu): ReLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","      (patch_embeddings): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): Encoder(\n","      (layer): ModuleList(\n","        (0): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (1): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (2): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (3): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (4): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (5): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (6): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (7): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (8): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (9): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (10): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","        (11): Block(\n","          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","          (ffn): Mlp(\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (attn): Attention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (out): Linear(in_features=768, out_features=768, bias=True)\n","            (attn_dropout): Dropout(p=0.0, inplace=False)\n","            (proj_dropout): Dropout(p=0.0, inplace=False)\n","            (softmax): Softmax(dim=-1)\n","          )\n","        )\n","      )\n","      (encoder_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","    )\n","  )\n","  (decoder): DecoderCup(\n","    (conv_more): Conv2dReLU(\n","      (0): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","    )\n","    (blocks): ModuleList(\n","      (0): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (up): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n","      )\n","      (1): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (up): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n","      )\n","      (2): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (up): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n","      )\n","      (3): DecoderBlock(\n","        (conv1): Conv2dReLU(\n","          (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (conv2): Conv2dReLU(\n","          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","        (up): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n","      )\n","    )\n","  )\n","  (segmentation_head): SegmentationHead(\n","    (0): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): Identity()\n","  )\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["checkloader = DataLoader(db_train, batch_size=25, shuffle=True, num_workers=1, pin_memory=True,\n","                        worker_init_fn=worker_init_fn)\n"],"metadata":{"id":"XIcCy1SsAdEx","executionInfo":{"status":"ok","timestamp":1644944368782,"user_tz":-120,"elapsed":14,"user":{"displayName":"Evyatar Burshtein","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15042063365769237452"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def test_sartorius():\n","\n","    dino_model.train()\n","    ce_loss = CrossEntropyLoss()\n","    dice_loss = DiceLoss(num_classes)\n","    \n","    iter_num = 0\n","\n","    loss = 0\n","\n","\n","    for i_batch, sampled_batch in enumerate(checkloader):\n","\n","        image_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n","        image_batch, label_batch = image_batch.cuda(), label_batch.cuda()\n","\n","        outputs = dino_model(image_batch)\n","\n","        loss_ce = ce_loss(outputs, label_batch[:].long())\n","        loss_dice = dice_loss(outputs, label_batch, softmax=True)\n","        curr_loss = 0.5 * loss_ce + 0.5 * loss_dice\n","        \n","        loss += curr_loss\n","\n","        iter_num = iter_num + 1\n","\n","        print(f\"iteration {iter_num} : loss : {curr_loss.item()}, loss_ce: {loss_ce.item()}\")\n","\n","    print(f\"\\nmean loss after {iter_num} iterations is - {loss.item()}\")"],"metadata":{"id":"nD15C4qA25NZ","executionInfo":{"status":"ok","timestamp":1644944368783,"user_tz":-120,"elapsed":14,"user":{"displayName":"Evyatar Burshtein","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15042063365769237452"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["test_sartorius()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"pU_FFCAoRxyz","executionInfo":{"status":"error","timestamp":1644944421191,"user_tz":-120,"elapsed":52422,"user":{"displayName":"Evyatar Burshtein","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15042063365769237452"}},"outputId":"2492308f-d6ab-4299-ba67-e52953297a7e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["iteration 1 : loss : 0.2710210084915161, loss_ce: 0.2610531151294708\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-78742103bbaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_sartorius\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-1a96d11f06d4>\u001b[0m in \u001b[0;36mtest_sartorius\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdino_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss_ce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Deep_learning/project/TransUnet_copy/networks/vit_seg_modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, n_patch, hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Deep_learning/project/TransUnet_copy/networks/vit_seg_modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, n_patch, hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Deep_learning/project/TransUnet_copy/networks/vit_seg_modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Deep_learning/project/TransUnet_copy/networks/vit_seg_modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Deep_learning/project/TransUnet_copy/networks/vit_seg_modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 11.17 GiB total capacity; 10.43 GiB already allocated; 8.81 MiB free; 10.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]}]}